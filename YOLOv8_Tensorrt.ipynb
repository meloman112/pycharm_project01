{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2gXjoyUkl1Wc"
   },
   "source": [
    "# YOLOv8 Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "OD26qSXamCfk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.15 🚀 Python-3.10.13 torch-2.2.0+cu121 CUDA:0 (NVIDIA GeForce RTX 4080, 16071MiB)\n",
      "Setup complete ✅ (32 CPUs, 62.6 GB RAM, 244.8/915.3 GB disk)\n"
     ]
    }
   ],
   "source": [
    "# Install YOLOv8\n",
    "#%pip install ultralytics\n",
    "\n",
    "import ultralytics\n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zJBju7PZmHYc"
   },
   "source": [
    "## Download the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "hHTp3kVsmKNi",
    "ExecuteTime": {
     "end_time": "2024-02-20T10:39:24.862476815Z",
     "start_time": "2024-02-20T10:39:20.268628585Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-02-20 15:39:20--  https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8x.pt\r\n",
      "Resolving github.com (github.com)... 140.82.121.4\r\n",
      "Connecting to github.com (github.com)|140.82.121.4|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 302 Found\r\n",
      "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/521807533/162e16dd-5d39-483d-8cd5-35ec1875bfbf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240220%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240220T103954Z&X-Amz-Expires=300&X-Amz-Signature=276858c807b91cae2575a51433b8d8d30403fbe35fbd3a9b2b9725fc37cf7cdc&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=521807533&response-content-disposition=attachment%3B%20filename%3Dyolov8x.pt&response-content-type=application%2Foctet-stream [following]\r\n",
      "--2024-02-20 15:39:21--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/521807533/162e16dd-5d39-483d-8cd5-35ec1875bfbf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240220%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240220T103954Z&X-Amz-Expires=300&X-Amz-Signature=276858c807b91cae2575a51433b8d8d30403fbe35fbd3a9b2b9725fc37cf7cdc&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=521807533&response-content-disposition=attachment%3B%20filename%3Dyolov8x.pt&response-content-type=application%2Foctet-stream\r\n",
      "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.108.133, ...\r\n",
      "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.109.133|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 136867539 (131M) [application/octet-stream]\r\n",
      "Saving to: ‘yolov8x.pt.1’\r\n",
      "\r\n",
      "yolov8x.pt.1          3%[                    ]   3.98M  3.66MB/s               ^C\r\n"
     ]
    }
   ],
   "source": [
    "# Download YOLOv8 model\n",
    "!wget https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8x.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9brSTmpEmLTj"
   },
   "source": [
    "# Tensorrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "VUff5dejmNHu",
    "ExecuteTime": {
     "end_time": "2024-02-26T08:24:08.289307896Z",
     "start_time": "2024-02-26T08:24:07.372323815Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorrt in ./.venv/lib/python3.10/site-packages (8.6.1.post1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "e0pZtlcCmQkE",
    "ExecuteTime": {
     "end_time": "2024-02-26T08:24:11.109420530Z",
     "start_time": "2024-02-26T08:24:10.252267450Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorrt_lean in ./.venv/lib/python3.10/site-packages (8.6.1.post1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorrt_lean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "fAhaRj11mS1m",
    "ExecuteTime": {
     "end_time": "2024-02-26T08:24:13.469656368Z",
     "start_time": "2024-02-26T08:24:12.601139552Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorrt_dispatch in ./.venv/lib/python3.10/site-packages (8.6.1.post1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorrt_dispatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "3zR8n35m5Kp6",
    "ExecuteTime": {
     "end_time": "2024-02-20T12:11:50.323172050Z",
     "start_time": "2024-02-20T12:11:49.482854489Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: onnx in ./.venv/lib/python3.10/site-packages (1.15.0)\r\n",
      "Requirement already satisfied: onnxsim in ./.venv/lib/python3.10/site-packages (0.4.35)\r\n",
      "Requirement already satisfied: onnxruntime-gpu in ./.venv/lib/python3.10/site-packages (1.17.0)\r\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.10/site-packages (from onnx) (1.26.4)\r\n",
      "Requirement already satisfied: protobuf>=3.20.2 in ./.venv/lib/python3.10/site-packages (from onnx) (4.25.3)\r\n",
      "Requirement already satisfied: rich in ./.venv/lib/python3.10/site-packages (from onnxsim) (13.7.0)\r\n",
      "Requirement already satisfied: coloredlogs in ./.venv/lib/python3.10/site-packages (from onnxruntime-gpu) (15.0.1)\r\n",
      "Requirement already satisfied: flatbuffers in ./.venv/lib/python3.10/site-packages (from onnxruntime-gpu) (23.5.26)\r\n",
      "Requirement already satisfied: packaging in ./.venv/lib/python3.10/site-packages (from onnxruntime-gpu) (23.2)\r\n",
      "Requirement already satisfied: sympy in ./.venv/lib/python3.10/site-packages (from onnxruntime-gpu) (1.12)\r\n",
      "Requirement already satisfied: humanfriendly>=9.1 in ./.venv/lib/python3.10/site-packages (from coloredlogs->onnxruntime-gpu) (10.0)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./.venv/lib/python3.10/site-packages (from rich->onnxsim) (3.0.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./.venv/lib/python3.10/site-packages (from rich->onnxsim) (2.17.2)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in ./.venv/lib/python3.10/site-packages (from sympy->onnxruntime-gpu) (1.3.0)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in ./.venv/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->onnxsim) (0.1.2)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install onnx onnxsim onnxruntime-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "2UxZjv9JmUaY",
    "ExecuteTime": {
     "end_time": "2024-02-26T08:24:20.101507780Z",
     "start_time": "2024-02-26T08:24:16.726252474Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.6.1\n"
     ]
    }
   ],
   "source": [
    "import tensorrt\n",
    "print(tensorrt.__version__)\n",
    "assert tensorrt.Builder(tensorrt.Logger())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "V62zTVoImXKU",
    "ExecuteTime": {
     "end_time": "2024-02-26T08:29:43.870125048Z",
     "start_time": "2024-02-26T08:24:39.555038581Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.15 🚀 Python-3.10.13 torch-2.2.0+cu121 CUDA:0 (NVIDIA GeForce RTX 4080, 16071MiB)\r\n",
      "YOLOv8m-pose summary (fused): 237 layers, 26447596 parameters, 0 gradients, 81.0 GFLOPs\r\n",
      "\r\n",
      "\u001B[34m\u001B[1mPyTorch:\u001B[0m starting from 'yolov8m-pose.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 56, 8400) (50.8 MB)\r\n",
      "\r\n",
      "\u001B[34m\u001B[1mONNX:\u001B[0m starting export with onnx 1.15.0 opset 17...\r\n",
      "\u001B[34m\u001B[1mONNX:\u001B[0m export success ✅ 0.8s, saved as 'yolov8m-pose.onnx' (101.2 MB)\r\n",
      "\r\n",
      "\u001B[34m\u001B[1mTensorRT:\u001B[0m starting export with TensorRT 8.6.1...\r\n",
      "[02/26/2024-13:24:42] [TRT] [I] [MemUsageChange] Init CUDA: CPU +1, GPU +0, now: CPU 904, GPU 1512 (MiB)\r\n",
      "[02/26/2024-13:24:45] [TRT] [I] [MemUsageChange] Init builder kernel library: CPU +1444, GPU +266, now: CPU 2425, GPU 1778 (MiB)\r\n",
      "[02/26/2024-13:24:45] [TRT] [I] ----------------------------------------------------------------\r\n",
      "[02/26/2024-13:24:45] [TRT] [I] Input filename:   yolov8m-pose.onnx\r\n",
      "[02/26/2024-13:24:45] [TRT] [I] ONNX IR version:  0.0.8\r\n",
      "[02/26/2024-13:24:45] [TRT] [I] Opset version:    17\r\n",
      "[02/26/2024-13:24:45] [TRT] [I] Producer name:    pytorch\r\n",
      "[02/26/2024-13:24:45] [TRT] [I] Producer version: 2.2.0\r\n",
      "[02/26/2024-13:24:45] [TRT] [I] Domain:           \r\n",
      "[02/26/2024-13:24:45] [TRT] [I] Model version:    0\r\n",
      "[02/26/2024-13:24:45] [TRT] [I] Doc string:       \r\n",
      "[02/26/2024-13:24:45] [TRT] [I] ----------------------------------------------------------------\r\n",
      "[02/26/2024-13:24:45] [TRT] [W] onnx2trt_utils.cpp:374: Your ONNX model has been generated with INT64 weights, while TensorRT does not natively support INT64. Attempting to cast down to INT32.\r\n",
      "\u001B[34m\u001B[1mTensorRT:\u001B[0m input \"images\" with shape(1, 3, 640, 640) DataType.FLOAT\r\n",
      "\u001B[34m\u001B[1mTensorRT:\u001B[0m output \"output0\" with shape(1, 56, 8400) DataType.FLOAT\r\n",
      "\u001B[34m\u001B[1mTensorRT:\u001B[0m building FP16 engine as yolov8m-pose.engine\r\n",
      "[02/26/2024-13:24:45] [TRT] [I] Graph optimization time: 0.0273001 seconds.\r\n",
      "[02/26/2024-13:24:45] [TRT] [I] Local timing cache in use. Profiling results in this builder pass will not be stored.\r\n",
      "[02/26/2024-13:29:42] [TRT] [I] Detected 1 inputs and 4 output network tensors.\r\n",
      "[02/26/2024-13:29:42] [TRT] [I] Total Host Persistent Memory: 518432\r\n",
      "[02/26/2024-13:29:42] [TRT] [I] Total Device Persistent Memory: 0\r\n",
      "[02/26/2024-13:29:42] [TRT] [I] Total Scratch Memory: 0\r\n",
      "[02/26/2024-13:29:42] [TRT] [I] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 63 MiB, GPU 157 MiB\r\n",
      "[02/26/2024-13:29:42] [TRT] [I] [BlockAssignment] Started assigning block shifts. This will take 150 steps to complete.\r\n",
      "[02/26/2024-13:29:42] [TRT] [I] [BlockAssignment] Algorithm ShiftNTopDown took 6.93588ms to assign 9 blocks to 150 nodes requiring 31334912 bytes.\r\n",
      "[02/26/2024-13:29:42] [TRT] [I] Total Activation Memory: 31334400\r\n",
      "[02/26/2024-13:29:43] [TRT] [W] TensorRT encountered issues when converting weights between types and that could affect accuracy.\r\n",
      "[02/26/2024-13:29:43] [TRT] [W] If this is not the desired behavior, please modify the weights or retrain with regularization to adjust the magnitude of the weights.\r\n",
      "[02/26/2024-13:29:43] [TRT] [W] Check verbose logs for the list of affected weights.\r\n",
      "[02/26/2024-13:29:43] [TRT] [W] - 82 weights are affected by this issue: Detected subnormal FP16 values.\r\n",
      "[02/26/2024-13:29:43] [TRT] [W] - 1 weights are affected by this issue: Detected values less than smallest positive FP16 subnormal value and converted them to the FP16 minimum subnormalized value.\r\n",
      "[02/26/2024-13:29:43] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in building engine: CPU +50, GPU +51, now: CPU 50, GPU 51 (MiB)\r\n",
      "\u001B[34m\u001B[1mTensorRT:\u001B[0m export success ✅ 301.8s, saved as 'yolov8m-pose.engine' (54.5 MB)\r\n",
      "\r\n",
      "Export complete (302.4s)\r\n",
      "Results saved to \u001B[1m/home/stargroup/new/camyolo\u001B[0m\r\n",
      "Predict:         yolo predict task=pose model=yolov8m-pose.engine imgsz=640 half \r\n",
      "Validate:        yolo val task=pose model=yolov8m-pose.engine imgsz=640 data=/usr/src/app/ultralytics/datasets/coco-pose.yaml half \r\n",
      "Visualize:       https://netron.app\r\n",
      "💡 Learn more at https://docs.ultralytics.com/modes/export\r\n"
     ]
    }
   ],
   "source": [
    "# Export YOLOv8 Model to Tensorrt\n",
    "!yolo export model=yolov8m-pose.pt format=engine half=True device=0 workspace=12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f8ZYA3k2mgz8"
   },
   "source": [
    "## Inference on Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "3DhS9BTRml_z",
    "ExecuteTime": {
     "end_time": "2024-02-20T12:20:38.812380776Z",
     "start_time": "2024-02-20T12:20:36.367513374Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ conflicting 'task=detect' passed with 'task=pose' model. Ignoring 'task=detect' and updating to 'task=pose' to match model.\r\n",
      "Ultralytics YOLOv8.1.15 🚀 Python-3.10.13 torch-2.2.0+cu121 CUDA:0 (NVIDIA GeForce RTX 4080, 16071MiB)\r\n",
      "YOLOv8n-pose summary (fused): 187 layers, 3289964 parameters, 0 gradients, 9.2 GFLOPs\r\n",
      "\r\n",
      "Found https://ultralytics.com/images/bus.jpg locally at bus.jpg\r\n",
      "image 1/1 /home/stargroup/new/camyolo/bus.jpg: 640x480 4 persons, 53.2ms\r\n",
      "Speed: 2.6ms preprocess, 53.2ms inference, 172.8ms postprocess per image at shape (1, 3, 640, 480)\r\n",
      "Results saved to \u001B[1mruns/pose/predict4\u001B[0m\r\n",
      "💡 Learn more at https://docs.ultralytics.com/modes/predict\r\n"
     ]
    }
   ],
   "source": [
    "# Inference Using YOLOv8 Model\n",
    "!yolo detect predict model=yolov8n-pose.pt source=\"https://ultralytics.com/images/bus.jpg\" device=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "-QIl5j75mvyB",
    "ExecuteTime": {
     "end_time": "2024-02-20T12:26:50.790590803Z",
     "start_time": "2024-02-20T12:26:48.657975242Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.15 🚀 Python-3.10.13 torch-2.2.0+cu121 CUDA:0 (NVIDIA GeForce RTX 4080, 16071MiB)\r\n",
      "Loading yolov8n-pose.engine for TensorRT inference...\r\n",
      "[02/20/2024-17:26:50] [TRT] [I] Loaded engine size: 9 MiB\r\n",
      "[02/20/2024-17:26:50] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +0, GPU +6, now: CPU 0, GPU 6 (MiB)\r\n",
      "[02/20/2024-17:26:50] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +11, now: CPU 0, GPU 17 (MiB)\r\n",
      "\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/home/stargroup/new/camyolo/.venv/bin/yolo\", line 8, in <module>\r\n",
      "    sys.exit(entrypoint())\r\n",
      "  File \"/home/stargroup/new/camyolo/.venv/lib/python3.10/site-packages/ultralytics/cfg/__init__.py\", line 568, in entrypoint\r\n",
      "    getattr(model, mode)(**overrides)  # default args from model\r\n",
      "  File \"/home/stargroup/new/camyolo/.venv/lib/python3.10/site-packages/ultralytics/engine/model.py\", line 406, in predict\r\n",
      "    return self.predictor.predict_cli(source=source) if is_cli else self.predictor(source=source, stream=stream)\r\n",
      "  File \"/home/stargroup/new/camyolo/.venv/lib/python3.10/site-packages/ultralytics/engine/predictor.py\", line 213, in predict_cli\r\n",
      "    for _ in gen:  # noqa, running CLI inference without accumulating any outputs (do not modify)\r\n",
      "  File \"/home/stargroup/new/camyolo/.venv/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 35, in generator_context\r\n",
      "    response = gen.send(None)\r\n",
      "  File \"/home/stargroup/new/camyolo/.venv/lib/python3.10/site-packages/ultralytics/engine/predictor.py\", line 306, in stream_inference\r\n",
      "    s += self.write_results(i, self.results, (p, im, im0))\r\n",
      "  File \"/home/stargroup/new/camyolo/.venv/lib/python3.10/site-packages/ultralytics/engine/predictor.py\", line 171, in write_results\r\n",
      "    log_string += result.verbose()\r\n",
      "  File \"/home/stargroup/new/camyolo/.venv/lib/python3.10/site-packages/ultralytics/engine/results.py\", line 327, in verbose\r\n",
      "    log_string += f\"{n} {self.names[int(c)]}{'s' * (n > 1)}, \"\r\n",
      "KeyError: 1\r\n"
     ]
    }
   ],
   "source": [
    "# Inference Using YOLOv8 Tensorrt\n",
    "!yolo detect predict model=yolov8n-pose.engine source=\"images/muxa/muxa1.jpg\" device=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "6uHSN2qk_ivN",
    "ExecuteTime": {
     "end_time": "2024-02-20T10:45:15.581642744Z",
     "start_time": "2024-02-20T10:45:15.345106480Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'runs/detect/predict2/bus.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[15], line 6\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m# Load the images\u001B[39;00m\n\u001B[1;32m      5\u001B[0m image1 \u001B[38;5;241m=\u001B[39m Image\u001B[38;5;241m.\u001B[39mopen(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mruns/detect/predict/bus.jpg\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m----> 6\u001B[0m image2 \u001B[38;5;241m=\u001B[39m \u001B[43mImage\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mopen\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mruns/detect/predict2/bus.jpg\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      8\u001B[0m w, h \u001B[38;5;241m=\u001B[39m image1\u001B[38;5;241m.\u001B[39msize\n\u001B[1;32m      9\u001B[0m new_width \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mint\u001B[39m(w\u001B[38;5;241m/\u001B[39m\u001B[38;5;241m2\u001B[39m)\n",
      "File \u001B[0;32m~/new/camyolo/.venv/lib/python3.10/site-packages/PIL/Image.py:3247\u001B[0m, in \u001B[0;36mopen\u001B[0;34m(fp, mode, formats)\u001B[0m\n\u001B[1;32m   3244\u001B[0m     filename \u001B[38;5;241m=\u001B[39m fp\n\u001B[1;32m   3246\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m filename:\n\u001B[0;32m-> 3247\u001B[0m     fp \u001B[38;5;241m=\u001B[39m \u001B[43mbuiltins\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrb\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3248\u001B[0m     exclusive_fp \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m   3250\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'runs/detect/predict2/bus.jpg'"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "\n",
    "# Load the images\n",
    "image1 = Image.open(\"runs/detect/predict/bus.jpg\")\n",
    "image2 = Image.open(\"runs/detect/predict2/bus.jpg\")\n",
    "\n",
    "w, h = image1.size\n",
    "new_width = int(w/2)\n",
    "new_height = int(h/2)\n",
    "\n",
    "# Resize the images\n",
    "image1 = image1.resize((new_width, new_height))\n",
    "image2 = image2.resize((new_width, new_height))\n",
    "\n",
    "# Display the images side by side\n",
    "display(image1, image2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t23v8tX4m3Bi"
   },
   "source": [
    "## mAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "L_VvMCQSm4Zy",
    "ExecuteTime": {
     "end_time": "2024-02-20T12:38:09.776200982Z",
     "start_time": "2024-02-20T12:37:32.916619704Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.1.0/yolov8x-pose.pt to 'yolov8x-pose.pt'...\r\n",
      "100%|████████████████████████████████████████| 133M/133M [00:30<00:00, 4.57MB/s]\r\n",
      "WARNING ⚠️ conflicting 'task=detect' passed with 'task=pose' model. Ignoring 'task=detect' and updating to 'task=pose' to match model.\r\n",
      "Ultralytics YOLOv8.1.15 🚀 Python-3.10.13 torch-2.2.0+cu121 CUDA:0 (NVIDIA GeForce RTX 4080, 16071MiB)\r\n",
      "YOLOv8x-pose summary (fused): 287 layers, 69462204 parameters, 0 gradients, 263.2 GFLOPs\r\n",
      "\u001B[34m\u001B[1mval: \u001B[0mScanning /home/stargroup/Azamat/pythonProject121/datasets/coco8-pose/labels\u001B[0m\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all          4         14      0.998      0.929      0.935      0.754      0.985      0.786      0.872      0.537\r\n",
      "Speed: 0.2ms preprocess, 16.9ms inference, 0.0ms loss, 36.0ms postprocess per image\r\n",
      "Results saved to \u001B[1mruns/pose/yolov8x3\u001B[0m\r\n",
      "💡 Learn more at https://docs.ultralytics.com/modes/val\r\n"
     ]
    }
   ],
   "source": [
    "# mAP Calculation YOLOv8 Model\n",
    "!yolo detect val model=yolov8x-pose.pt data=coco8-pose.yaml iou=0.5 imgsz=640 name=yolov8x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "O0LDOtg8nGE2",
    "ExecuteTime": {
     "end_time": "2024-02-20T12:29:29.213952377Z",
     "start_time": "2024-02-20T12:29:26.914950199Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.15 🚀 Python-3.10.13 torch-2.2.0+cu121 CUDA:0 (NVIDIA GeForce RTX 4080, 16071MiB)\r\n",
      "Loading yolov8n-pose.engine for TensorRT inference...\r\n",
      "[02/20/2024-17:29:28] [TRT] [I] Loaded engine size: 9 MiB\r\n",
      "[02/20/2024-17:29:28] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +0, GPU +6, now: CPU 0, GPU 6 (MiB)\r\n",
      "[02/20/2024-17:29:28] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +11, now: CPU 0, GPU 17 (MiB)\r\n",
      "\u001B[34m\u001B[1mval: \u001B[0mScanning /home/stargroup/Azamat/pythonProject121/datasets/coco8-pose/labels\u001B[0m\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/home/stargroup/new/camyolo/.venv/bin/yolo\", line 8, in <module>\r\n",
      "    sys.exit(entrypoint())\r\n",
      "  File \"/home/stargroup/new/camyolo/.venv/lib/python3.10/site-packages/ultralytics/cfg/__init__.py\", line 568, in entrypoint\r\n",
      "    getattr(model, mode)(**overrides)  # default args from model\r\n",
      "  File \"/home/stargroup/new/camyolo/.venv/lib/python3.10/site-packages/ultralytics/engine/model.py\", line 470, in val\r\n",
      "    validator(model=self.model)\r\n",
      "  File \"/home/stargroup/new/camyolo/.venv/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\r\n",
      "    return func(*args, **kwargs)\r\n",
      "  File \"/home/stargroup/new/camyolo/.venv/lib/python3.10/site-packages/ultralytics/engine/validator.py\", line 187, in __call__\r\n",
      "    self.update_metrics(preds, batch)\r\n",
      "  File \"/home/stargroup/new/camyolo/.venv/lib/python3.10/site-packages/ultralytics/models/yolo/detect/val.py\", line 152, in update_metrics\r\n",
      "    self.confusion_matrix.process_batch(predn, bbox, cls)\r\n",
      "  File \"/home/stargroup/new/camyolo/.venv/lib/python3.10/site-packages/ultralytics/utils/metrics.py\", line 368, in process_batch\r\n",
      "    self.matrix[detection_classes[m1[j]], gc] += 1  # correct\r\n",
      "IndexError: index 22 is out of bounds for axis 0 with size 2\r\n"
     ]
    }
   ],
   "source": [
    "# mAP Calculation YOLOv8 Tensorrt\n",
    "!yolo detect val model=yolov8n-pose.engine data=coco8-pose.yaml iou=0.5 imgsz=640 name=yolov8x-tensorrt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z7GeHBg_m4km"
   },
   "source": [
    "## Inference on Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a1PyUqCanKJW",
    "ExecuteTime": {
     "start_time": "2024-02-20T10:45:15.583549434Z"
    }
   },
   "outputs": [],
   "source": [
    "# Download modules\n",
    "!gdown https://drive.google.com/uc?id=1RskX1wXVF0xSMAPgpkU-EsaUv8tD7lvS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "khIoR0ccnKWK",
    "ExecuteTime": {
     "start_time": "2024-02-20T10:45:15.584249828Z"
    }
   },
   "outputs": [],
   "source": [
    "# Unzip the modules\n",
    "!unzip modules.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ywuQHtHukaAj",
    "ExecuteTime": {
     "start_time": "2024-02-20T10:45:15.585023359Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create inference folder\n",
    "!mkdir inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zANblaROkbTH",
    "ExecuteTime": {
     "start_time": "2024-02-20T10:45:15.585801501Z"
    }
   },
   "outputs": [],
   "source": [
    "# Download the video\n",
    "!gdown https://drive.google.com/uc?id=11Z0BMXcKNdQmJNyBejWqU9V6z7gEloMZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N9KXMeCKke7L",
    "ExecuteTime": {
     "end_time": "2024-02-20T10:45:15.586999793Z",
     "start_time": "2024-02-20T10:45:15.586572033Z"
    }
   },
   "outputs": [],
   "source": [
    "# Move the video to inference folder\n",
    "!mv road.mp4 inference/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L3HtPyVwkleD",
    "ExecuteTime": {
     "start_time": "2024-02-20T10:45:15.587343181Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import random\n",
    "import time\n",
    "import pathlib\n",
    "from ultralytics import YOLO\n",
    "\n",
    "import modules.utils as utils\n",
    "from modules.autobackend import AutoBackend\n",
    "\n",
    "def tensorrt_detection(model, source, image):\n",
    "    # Preprocess\n",
    "    im = utils.preprocess(image)\n",
    "\n",
    "    # Inference\n",
    "    preds = model(im)\n",
    "\n",
    "    # Post Process\n",
    "    results = utils.postprocess(preds, im, image, model.names, source)\n",
    "    d = results[0].boxes\n",
    "\n",
    "    # Get information from result\n",
    "    tensor_size = d.cls.size()[0]\n",
    "    if(tensor_size > 1):\n",
    "        cls, conf, box = d.cls.squeeze(), d.conf.squeeze(), d.xyxy.squeeze()\n",
    "    else:\n",
    "        cls, conf, box = d.cls, d.conf, d.xyxy\n",
    "\n",
    "    return cls, conf, box\n",
    "\n",
    "def yolov8_detection(model, image):\n",
    "    # Update object localizer\n",
    "    results = model.predict(image, imgsz=640, conf=0.5, verbose=False)\n",
    "    result = results[0].cpu()\n",
    "\n",
    "    # Get information from result\n",
    "    box = result.boxes.xyxy.numpy()\n",
    "    conf = result.boxes.conf.numpy()\n",
    "    cls = result.boxes.cls.numpy().astype(int)\n",
    "\n",
    "    return cls, conf, box\n",
    "\n",
    "def detection(model_path, source, name):\n",
    "  # Check File Extension\n",
    "  file_extension = pathlib.Path(model_path).suffix\n",
    "\n",
    "  if(file_extension == \".engine\"):\n",
    "    model = AutoBackend(model_path, device=torch.device('cuda:0'), fp16=True)\n",
    "    # Warmup\n",
    "    model.warmup()\n",
    "  else:\n",
    "    model = YOLO(model_path)\n",
    "\n",
    "  # Class Name and Colors\n",
    "  label_map = model.names\n",
    "  COLORS = [[random.randint(0, 255) for _ in range(3)] for _ in label_map]\n",
    "\n",
    "  # FPS Detection\n",
    "  frame_count = 0\n",
    "  total_fps = 0\n",
    "  avg_fps = 0\n",
    "\n",
    "  # FPS Video\n",
    "  video_cap = cv2.VideoCapture(source)\n",
    "\n",
    "  total_frames = int(video_cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "  frame_width = int(video_cap.get(3))\n",
    "  frame_height = int(video_cap.get(4))\n",
    "\n",
    "  video_frames = []\n",
    "\n",
    "  while video_cap.isOpened():\n",
    "      ret, frame = video_cap.read()\n",
    "      if not ret:\n",
    "          break\n",
    "\n",
    "      # # Start Time\n",
    "      start = time.time()\n",
    "\n",
    "      # Detection\n",
    "      if(file_extension == \".engine\"):\n",
    "        cls, conf, box = tensorrt_detection(model, source, frame)\n",
    "      else:\n",
    "        cls, conf, box = yolov8_detection(model, frame)\n",
    "\n",
    "      # Pack together for easy use\n",
    "      detection_output = list(zip(cls, conf, box))\n",
    "      image_output = utils.draw_box(frame, detection_output, label_map, COLORS)\n",
    "\n",
    "      end = time.time()\n",
    "      # # End Time\n",
    "\n",
    "      # Draw FPS\n",
    "      frame_count += 1\n",
    "      fps = 1 / (end - start)\n",
    "      total_fps = total_fps + fps\n",
    "      avg_fps = total_fps / frame_count\n",
    "\n",
    "      image_output = utils.draw_fps(avg_fps, image_output)\n",
    "\n",
    "      # Append frame to array\n",
    "      video_frames.append(image_output)\n",
    "\n",
    "      #\n",
    "      print(\"(%2d / %2d) Frames Processed\" % (frame_count, total_frames))\n",
    "\n",
    "  print(avg_fps)\n",
    "\n",
    "  # Get a file name\n",
    "  file_name = utils.get_name(source)\n",
    "  # Get Save Path\n",
    "  folder_name = name\n",
    "  save_path = utils.get_save_path(file_name, folder_name)\n",
    "  # Create VideoWriter object.\n",
    "  out = cv2.VideoWriter(save_path, cv2.VideoWriter_fourcc(*'XVID'), int(avg_fps), (frame_width, frame_height))\n",
    "\n",
    "  for frame in video_frames:\n",
    "      out.write(frame)\n",
    "\n",
    "  out.release()\n",
    "\n",
    "  print(\"Video is saved in: \"+save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fcl651SGko9V",
    "ExecuteTime": {
     "start_time": "2024-02-20T10:45:15.588141999Z"
    }
   },
   "outputs": [],
   "source": [
    "detection(\"yolov8x.pt\", \"inference/road.mp4\", \"detection-yolov8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NTZH7sCHkpfr",
    "ExecuteTime": {
     "start_time": "2024-02-20T10:45:15.590779124Z"
    }
   },
   "outputs": [],
   "source": [
    "# Download the result\n",
    "from google.colab import files\n",
    "\n",
    "files.download('result/detection-yolov8/road.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_9UVb02-nKaw",
    "ExecuteTime": {
     "start_time": "2024-02-20T10:45:15.590849167Z"
    }
   },
   "outputs": [],
   "source": [
    "detection(\"yolov8x.engine\", \"inference/road.mp4\", \"detection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xjv-OcATnKdD",
    "ExecuteTime": {
     "start_time": "2024-02-20T10:45:15.590875082Z"
    }
   },
   "outputs": [],
   "source": [
    "# Download the result\n",
    "from google.colab import files\n",
    "\n",
    "files.download('result/detection/road.mp4')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
