{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2gXjoyUkl1Wc"
   },
   "source": [
    "# YOLOv8 Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "OD26qSXamCfk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.15 ðŸš€ Python-3.10.13 torch-2.2.0+cu121 CUDA:0 (NVIDIA GeForce RTX 4080, 16071MiB)\n",
      "Setup complete âœ… (32 CPUs, 62.6 GB RAM, 191.6/915.3 GB disk)\n"
     ]
    }
   ],
   "source": [
    "# Install YOLOv8\n",
    "%pip install ultralytics\n",
    "\n",
    "import ultralytics\n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zJBju7PZmHYc"
   },
   "source": [
    "## Download the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "hHTp3kVsmKNi",
    "ExecuteTime": {
     "end_time": "2024-02-20T10:39:24.862476815Z",
     "start_time": "2024-02-20T10:39:20.268628585Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-02-20 15:39:20--  https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8x.pt\r\n",
      "Resolving github.com (github.com)... 140.82.121.4\r\n",
      "Connecting to github.com (github.com)|140.82.121.4|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 302 Found\r\n",
      "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/521807533/162e16dd-5d39-483d-8cd5-35ec1875bfbf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240220%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240220T103954Z&X-Amz-Expires=300&X-Amz-Signature=276858c807b91cae2575a51433b8d8d30403fbe35fbd3a9b2b9725fc37cf7cdc&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=521807533&response-content-disposition=attachment%3B%20filename%3Dyolov8x.pt&response-content-type=application%2Foctet-stream [following]\r\n",
      "--2024-02-20 15:39:21--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/521807533/162e16dd-5d39-483d-8cd5-35ec1875bfbf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240220%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240220T103954Z&X-Amz-Expires=300&X-Amz-Signature=276858c807b91cae2575a51433b8d8d30403fbe35fbd3a9b2b9725fc37cf7cdc&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=521807533&response-content-disposition=attachment%3B%20filename%3Dyolov8x.pt&response-content-type=application%2Foctet-stream\r\n",
      "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.108.133, ...\r\n",
      "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.109.133|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 136867539 (131M) [application/octet-stream]\r\n",
      "Saving to: â€˜yolov8x.pt.1â€™\r\n",
      "\r\n",
      "yolov8x.pt.1          3%[                    ]   3.98M  3.66MB/s               ^C\r\n"
     ]
    }
   ],
   "source": [
    "# Download YOLOv8 model\n",
    "!wget https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8x.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9brSTmpEmLTj"
   },
   "source": [
    "# Tensorrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "VUff5dejmNHu",
    "ExecuteTime": {
     "end_time": "2024-02-20T12:11:42.433902700Z",
     "start_time": "2024-02-20T12:11:41.586900149Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorrt in ./.venv/lib/python3.10/site-packages (8.6.1.post1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "e0pZtlcCmQkE",
    "ExecuteTime": {
     "end_time": "2024-02-20T12:11:46.739437492Z",
     "start_time": "2024-02-20T12:11:45.906398478Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorrt_lean in ./.venv/lib/python3.10/site-packages (8.6.1.post1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorrt_lean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "fAhaRj11mS1m",
    "ExecuteTime": {
     "end_time": "2024-02-20T12:11:48.477723832Z",
     "start_time": "2024-02-20T12:11:47.655696546Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorrt_dispatch in ./.venv/lib/python3.10/site-packages (8.6.1.post1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorrt_dispatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "3zR8n35m5Kp6",
    "ExecuteTime": {
     "end_time": "2024-02-20T12:11:50.323172050Z",
     "start_time": "2024-02-20T12:11:49.482854489Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: onnx in ./.venv/lib/python3.10/site-packages (1.15.0)\r\n",
      "Requirement already satisfied: onnxsim in ./.venv/lib/python3.10/site-packages (0.4.35)\r\n",
      "Requirement already satisfied: onnxruntime-gpu in ./.venv/lib/python3.10/site-packages (1.17.0)\r\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.10/site-packages (from onnx) (1.26.4)\r\n",
      "Requirement already satisfied: protobuf>=3.20.2 in ./.venv/lib/python3.10/site-packages (from onnx) (4.25.3)\r\n",
      "Requirement already satisfied: rich in ./.venv/lib/python3.10/site-packages (from onnxsim) (13.7.0)\r\n",
      "Requirement already satisfied: coloredlogs in ./.venv/lib/python3.10/site-packages (from onnxruntime-gpu) (15.0.1)\r\n",
      "Requirement already satisfied: flatbuffers in ./.venv/lib/python3.10/site-packages (from onnxruntime-gpu) (23.5.26)\r\n",
      "Requirement already satisfied: packaging in ./.venv/lib/python3.10/site-packages (from onnxruntime-gpu) (23.2)\r\n",
      "Requirement already satisfied: sympy in ./.venv/lib/python3.10/site-packages (from onnxruntime-gpu) (1.12)\r\n",
      "Requirement already satisfied: humanfriendly>=9.1 in ./.venv/lib/python3.10/site-packages (from coloredlogs->onnxruntime-gpu) (10.0)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./.venv/lib/python3.10/site-packages (from rich->onnxsim) (3.0.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./.venv/lib/python3.10/site-packages (from rich->onnxsim) (2.17.2)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in ./.venv/lib/python3.10/site-packages (from sympy->onnxruntime-gpu) (1.3.0)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in ./.venv/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->onnxsim) (0.1.2)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install onnx onnxsim onnxruntime-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "2UxZjv9JmUaY",
    "ExecuteTime": {
     "end_time": "2024-02-20T12:11:55.060583203Z",
     "start_time": "2024-02-20T12:11:51.697661403Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.6.1\n"
     ]
    }
   ],
   "source": [
    "import tensorrt\n",
    "print(tensorrt.__version__)\n",
    "assert tensorrt.Builder(tensorrt.Logger())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V62zTVoImXKU",
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-02-20T12:12:06.024201627Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.15 ðŸš€ Python-3.10.13 torch-2.2.0+cu121 CUDA:0 (NVIDIA GeForce RTX 4080, 16071MiB)\r\n",
      "YOLOv8n-pose summary (fused): 187 layers, 3289964 parameters, 0 gradients, 9.2 GFLOPs\r\n",
      "\r\n",
      "\u001B[34m\u001B[1mPyTorch:\u001B[0m starting from 'yolov8n-pose.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 56, 8400) (6.5 MB)\r\n",
      "\r\n",
      "\u001B[34m\u001B[1mONNX:\u001B[0m starting export with onnx 1.15.0 opset 17...\r\n",
      "\u001B[34m\u001B[1mONNX:\u001B[0m export success âœ… 0.3s, saved as 'yolov8n-pose.onnx' (12.9 MB)\r\n",
      "\r\n",
      "\u001B[34m\u001B[1mTensorRT:\u001B[0m starting export with TensorRT 8.6.1...\r\n",
      "[02/20/2024-17:12:08] [TRT] [I] [MemUsageChange] Init CUDA: CPU +1, GPU +0, now: CPU 681, GPU 1374 (MiB)\r\n",
      "[02/20/2024-17:12:11] [TRT] [I] [MemUsageChange] Init builder kernel library: CPU +1444, GPU +266, now: CPU 2202, GPU 1640 (MiB)\r\n",
      "[02/20/2024-17:12:11] [TRT] [I] ----------------------------------------------------------------\r\n",
      "[02/20/2024-17:12:11] [TRT] [I] Input filename:   yolov8n-pose.onnx\r\n",
      "[02/20/2024-17:12:11] [TRT] [I] ONNX IR version:  0.0.8\r\n",
      "[02/20/2024-17:12:11] [TRT] [I] Opset version:    17\r\n",
      "[02/20/2024-17:12:11] [TRT] [I] Producer name:    pytorch\r\n",
      "[02/20/2024-17:12:11] [TRT] [I] Producer version: 2.2.0\r\n",
      "[02/20/2024-17:12:11] [TRT] [I] Domain:           \r\n",
      "[02/20/2024-17:12:11] [TRT] [I] Model version:    0\r\n",
      "[02/20/2024-17:12:11] [TRT] [I] Doc string:       \r\n",
      "[02/20/2024-17:12:11] [TRT] [I] ----------------------------------------------------------------\r\n",
      "[02/20/2024-17:12:11] [TRT] [W] onnx2trt_utils.cpp:374: Your ONNX model has been generated with INT64 weights, while TensorRT does not natively support INT64. Attempting to cast down to INT32.\r\n",
      "\u001B[34m\u001B[1mTensorRT:\u001B[0m input \"images\" with shape(1, 3, 640, 640) DataType.FLOAT\r\n",
      "\u001B[34m\u001B[1mTensorRT:\u001B[0m output \"output0\" with shape(1, 56, 8400) DataType.FLOAT\r\n",
      "\u001B[34m\u001B[1mTensorRT:\u001B[0m building FP16 engine as yolov8n-pose.engine\r\n",
      "[02/20/2024-17:12:11] [TRT] [I] Graph optimization time: 0.0155387 seconds.\r\n",
      "[02/20/2024-17:12:11] [TRT] [I] Local timing cache in use. Profiling results in this builder pass will not be stored.\r\n"
     ]
    }
   ],
   "source": [
    "# Export YOLOv8 Model to Tensorrt\n",
    "!yolo export model=yolov8n-pose.pt format=engine half=True device=0 workspace=12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f8ZYA3k2mgz8"
   },
   "source": [
    "## Inference on Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "3DhS9BTRml_z",
    "ExecuteTime": {
     "end_time": "2024-02-20T12:04:10.864297934Z",
     "start_time": "2024-02-20T12:04:08.271472907Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING âš ï¸ conflicting 'task=detect' passed with 'task=pose' model. Ignoring 'task=detect' and updating to 'task=pose' to match model.\r\n",
      "Ultralytics YOLOv8.1.15 ðŸš€ Python-3.10.13 torch-2.2.0+cu121 CUDA:0 (NVIDIA GeForce RTX 4080, 16071MiB)\r\n",
      "YOLOv8n-pose summary (fused): 187 layers, 3289964 parameters, 0 gradients, 9.2 GFLOPs\r\n",
      "\r\n",
      "Found https://ultralytics.com/images/bus.jpg locally at bus.jpg\r\n",
      "image 1/1 /home/stargroup/new/camyolo/bus.jpg: 640x480 4 persons, 51.3ms\r\n",
      "Speed: 1.5ms preprocess, 51.3ms inference, 245.0ms postprocess per image at shape (1, 3, 640, 480)\r\n",
      "Results saved to \u001B[1mruns/pose/predict3\u001B[0m\r\n",
      "ðŸ’¡ Learn more at https://docs.ultralytics.com/modes/predict\r\n"
     ]
    }
   ],
   "source": [
    "# Inference Using YOLOv8 Model\n",
    "!yolo detect predict model=yolov8n-pose.pt source=\"https://ultralytics.com/images/bus.jpg\" device=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "-QIl5j75mvyB",
    "ExecuteTime": {
     "end_time": "2024-02-20T11:58:49.953302091Z",
     "start_time": "2024-02-20T11:58:48.031255315Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.15 ðŸš€ Python-3.10.13 torch-2.2.0+cu121 CUDA:0 (NVIDIA GeForce RTX 4080, 16071MiB)\r\n",
      "Loading yolov8x.engine for TensorRT inference...\r\n",
      "[02/20/2024-16:58:49] [TRT] [I] Loaded engine size: 133 MiB\r\n",
      "[02/20/2024-16:58:49] [TRT] [E] 6: The engine plan file is generated on an incompatible device, expecting compute 8.9 got compute 7.5, please rebuild.\r\n",
      "[02/20/2024-16:58:49] [TRT] [E] 2: [engine.cpp::deserializeEngine::951] Error Code 2: Internal Error (Assertion engine->deserialize(start, size, allocator, runtime) failed. )\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/home/stargroup/new/camyolo/.venv/bin/yolo\", line 8, in <module>\r\n",
      "    sys.exit(entrypoint())\r\n",
      "  File \"/home/stargroup/new/camyolo/.venv/lib/python3.10/site-packages/ultralytics/cfg/__init__.py\", line 568, in entrypoint\r\n",
      "    getattr(model, mode)(**overrides)  # default args from model\r\n",
      "  File \"/home/stargroup/new/camyolo/.venv/lib/python3.10/site-packages/ultralytics/engine/model.py\", line 399, in predict\r\n",
      "    self.predictor.setup_model(model=self.model, verbose=is_cli)\r\n",
      "  File \"/home/stargroup/new/camyolo/.venv/lib/python3.10/site-packages/ultralytics/engine/predictor.py\", line 341, in setup_model\r\n",
      "    self.model = AutoBackend(\r\n",
      "  File \"/home/stargroup/new/camyolo/.venv/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\r\n",
      "    return func(*args, **kwargs)\r\n",
      "  File \"/home/stargroup/new/camyolo/.venv/lib/python3.10/site-packages/ultralytics/nn/autobackend.py\", line 216, in __init__\r\n",
      "    context = model.create_execution_context()\r\n",
      "AttributeError: 'NoneType' object has no attribute 'create_execution_context'\r\n"
     ]
    }
   ],
   "source": [
    "# Inference Using YOLOv8 Tensorrt\n",
    "!yolo detect predict model=yolov8x.engine source=\"https://ultralytics.com/images/bus.jpg\" device=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "6uHSN2qk_ivN",
    "ExecuteTime": {
     "end_time": "2024-02-20T10:45:15.581642744Z",
     "start_time": "2024-02-20T10:45:15.345106480Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'runs/detect/predict2/bus.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[15], line 6\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m# Load the images\u001B[39;00m\n\u001B[1;32m      5\u001B[0m image1 \u001B[38;5;241m=\u001B[39m Image\u001B[38;5;241m.\u001B[39mopen(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mruns/detect/predict/bus.jpg\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m----> 6\u001B[0m image2 \u001B[38;5;241m=\u001B[39m \u001B[43mImage\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mopen\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mruns/detect/predict2/bus.jpg\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      8\u001B[0m w, h \u001B[38;5;241m=\u001B[39m image1\u001B[38;5;241m.\u001B[39msize\n\u001B[1;32m      9\u001B[0m new_width \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mint\u001B[39m(w\u001B[38;5;241m/\u001B[39m\u001B[38;5;241m2\u001B[39m)\n",
      "File \u001B[0;32m~/new/camyolo/.venv/lib/python3.10/site-packages/PIL/Image.py:3247\u001B[0m, in \u001B[0;36mopen\u001B[0;34m(fp, mode, formats)\u001B[0m\n\u001B[1;32m   3244\u001B[0m     filename \u001B[38;5;241m=\u001B[39m fp\n\u001B[1;32m   3246\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m filename:\n\u001B[0;32m-> 3247\u001B[0m     fp \u001B[38;5;241m=\u001B[39m \u001B[43mbuiltins\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrb\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3248\u001B[0m     exclusive_fp \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m   3250\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'runs/detect/predict2/bus.jpg'"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "\n",
    "# Load the images\n",
    "image1 = Image.open(\"runs/detect/predict/bus.jpg\")\n",
    "image2 = Image.open(\"runs/detect/predict2/bus.jpg\")\n",
    "\n",
    "w, h = image1.size\n",
    "new_width = int(w/2)\n",
    "new_height = int(h/2)\n",
    "\n",
    "# Resize the images\n",
    "image1 = image1.resize((new_width, new_height))\n",
    "image2 = image2.resize((new_width, new_height))\n",
    "\n",
    "# Display the images side by side\n",
    "display(image1, image2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t23v8tX4m3Bi"
   },
   "source": [
    "## mAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L_VvMCQSm4Zy",
    "ExecuteTime": {
     "start_time": "2024-02-20T10:45:15.582098337Z"
    }
   },
   "outputs": [],
   "source": [
    "# mAP Calculation YOLOv8 Model\n",
    "!yolo detect val model=yolov8x.pt data=coco128.yaml iou=0.5 imgsz=640 name=yolov8x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O0LDOtg8nGE2",
    "ExecuteTime": {
     "end_time": "2024-02-20T10:45:15.586367614Z",
     "start_time": "2024-02-20T10:45:15.582671344Z"
    }
   },
   "outputs": [],
   "source": [
    "# mAP Calculation YOLOv8 Tensorrt\n",
    "!yolo detect val model=yolov8x.engine data=coco128.yaml iou=0.5 imgsz=640 name=yolov8x-tensorrt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z7GeHBg_m4km"
   },
   "source": [
    "## Inference on Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a1PyUqCanKJW",
    "ExecuteTime": {
     "start_time": "2024-02-20T10:45:15.583549434Z"
    }
   },
   "outputs": [],
   "source": [
    "# Download modules\n",
    "!gdown https://drive.google.com/uc?id=1RskX1wXVF0xSMAPgpkU-EsaUv8tD7lvS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "khIoR0ccnKWK",
    "ExecuteTime": {
     "start_time": "2024-02-20T10:45:15.584249828Z"
    }
   },
   "outputs": [],
   "source": [
    "# Unzip the modules\n",
    "!unzip modules.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ywuQHtHukaAj",
    "ExecuteTime": {
     "start_time": "2024-02-20T10:45:15.585023359Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create inference folder\n",
    "!mkdir inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zANblaROkbTH",
    "ExecuteTime": {
     "start_time": "2024-02-20T10:45:15.585801501Z"
    }
   },
   "outputs": [],
   "source": [
    "# Download the video\n",
    "!gdown https://drive.google.com/uc?id=11Z0BMXcKNdQmJNyBejWqU9V6z7gEloMZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N9KXMeCKke7L",
    "ExecuteTime": {
     "end_time": "2024-02-20T10:45:15.586999793Z",
     "start_time": "2024-02-20T10:45:15.586572033Z"
    }
   },
   "outputs": [],
   "source": [
    "# Move the video to inference folder\n",
    "!mv road.mp4 inference/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L3HtPyVwkleD",
    "ExecuteTime": {
     "start_time": "2024-02-20T10:45:15.587343181Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import random\n",
    "import time\n",
    "import pathlib\n",
    "from ultralytics import YOLO\n",
    "\n",
    "import modules.utils as utils\n",
    "from modules.autobackend import AutoBackend\n",
    "\n",
    "def tensorrt_detection(model, source, image):\n",
    "    # Preprocess\n",
    "    im = utils.preprocess(image)\n",
    "\n",
    "    # Inference\n",
    "    preds = model(im)\n",
    "\n",
    "    # Post Process\n",
    "    results = utils.postprocess(preds, im, image, model.names, source)\n",
    "    d = results[0].boxes\n",
    "\n",
    "    # Get information from result\n",
    "    tensor_size = d.cls.size()[0]\n",
    "    if(tensor_size > 1):\n",
    "        cls, conf, box = d.cls.squeeze(), d.conf.squeeze(), d.xyxy.squeeze()\n",
    "    else:\n",
    "        cls, conf, box = d.cls, d.conf, d.xyxy\n",
    "\n",
    "    return cls, conf, box\n",
    "\n",
    "def yolov8_detection(model, image):\n",
    "    # Update object localizer\n",
    "    results = model.predict(image, imgsz=640, conf=0.5, verbose=False)\n",
    "    result = results[0].cpu()\n",
    "\n",
    "    # Get information from result\n",
    "    box = result.boxes.xyxy.numpy()\n",
    "    conf = result.boxes.conf.numpy()\n",
    "    cls = result.boxes.cls.numpy().astype(int)\n",
    "\n",
    "    return cls, conf, box\n",
    "\n",
    "def detection(model_path, source, name):\n",
    "  # Check File Extension\n",
    "  file_extension = pathlib.Path(model_path).suffix\n",
    "\n",
    "  if(file_extension == \".engine\"):\n",
    "    model = AutoBackend(model_path, device=torch.device('cuda:0'), fp16=True)\n",
    "    # Warmup\n",
    "    model.warmup()\n",
    "  else:\n",
    "    model = YOLO(model_path)\n",
    "\n",
    "  # Class Name and Colors\n",
    "  label_map = model.names\n",
    "  COLORS = [[random.randint(0, 255) for _ in range(3)] for _ in label_map]\n",
    "\n",
    "  # FPS Detection\n",
    "  frame_count = 0\n",
    "  total_fps = 0\n",
    "  avg_fps = 0\n",
    "\n",
    "  # FPS Video\n",
    "  video_cap = cv2.VideoCapture(source)\n",
    "\n",
    "  total_frames = int(video_cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "  frame_width = int(video_cap.get(3))\n",
    "  frame_height = int(video_cap.get(4))\n",
    "\n",
    "  video_frames = []\n",
    "\n",
    "  while video_cap.isOpened():\n",
    "      ret, frame = video_cap.read()\n",
    "      if not ret:\n",
    "          break\n",
    "\n",
    "      # # Start Time\n",
    "      start = time.time()\n",
    "\n",
    "      # Detection\n",
    "      if(file_extension == \".engine\"):\n",
    "        cls, conf, box = tensorrt_detection(model, source, frame)\n",
    "      else:\n",
    "        cls, conf, box = yolov8_detection(model, frame)\n",
    "\n",
    "      # Pack together for easy use\n",
    "      detection_output = list(zip(cls, conf, box))\n",
    "      image_output = utils.draw_box(frame, detection_output, label_map, COLORS)\n",
    "\n",
    "      end = time.time()\n",
    "      # # End Time\n",
    "\n",
    "      # Draw FPS\n",
    "      frame_count += 1\n",
    "      fps = 1 / (end - start)\n",
    "      total_fps = total_fps + fps\n",
    "      avg_fps = total_fps / frame_count\n",
    "\n",
    "      image_output = utils.draw_fps(avg_fps, image_output)\n",
    "\n",
    "      # Append frame to array\n",
    "      video_frames.append(image_output)\n",
    "\n",
    "      #\n",
    "      print(\"(%2d / %2d) Frames Processed\" % (frame_count, total_frames))\n",
    "\n",
    "  print(avg_fps)\n",
    "\n",
    "  # Get a file name\n",
    "  file_name = utils.get_name(source)\n",
    "  # Get Save Path\n",
    "  folder_name = name\n",
    "  save_path = utils.get_save_path(file_name, folder_name)\n",
    "  # Create VideoWriter object.\n",
    "  out = cv2.VideoWriter(save_path, cv2.VideoWriter_fourcc(*'XVID'), int(avg_fps), (frame_width, frame_height))\n",
    "\n",
    "  for frame in video_frames:\n",
    "      out.write(frame)\n",
    "\n",
    "  out.release()\n",
    "\n",
    "  print(\"Video is saved in: \"+save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fcl651SGko9V",
    "ExecuteTime": {
     "start_time": "2024-02-20T10:45:15.588141999Z"
    }
   },
   "outputs": [],
   "source": [
    "detection(\"yolov8x.pt\", \"inference/road.mp4\", \"detection-yolov8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NTZH7sCHkpfr",
    "ExecuteTime": {
     "start_time": "2024-02-20T10:45:15.590779124Z"
    }
   },
   "outputs": [],
   "source": [
    "# Download the result\n",
    "from google.colab import files\n",
    "\n",
    "files.download('result/detection-yolov8/road.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_9UVb02-nKaw",
    "ExecuteTime": {
     "start_time": "2024-02-20T10:45:15.590849167Z"
    }
   },
   "outputs": [],
   "source": [
    "detection(\"yolov8x.engine\", \"inference/road.mp4\", \"detection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xjv-OcATnKdD",
    "ExecuteTime": {
     "start_time": "2024-02-20T10:45:15.590875082Z"
    }
   },
   "outputs": [],
   "source": [
    "# Download the result\n",
    "from google.colab import files\n",
    "\n",
    "files.download('result/detection/road.mp4')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
